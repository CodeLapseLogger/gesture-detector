# Gesture Detector to enable accessibility workflows in web apps

This is a hand gesture detection react app, that leverages pre-built Tensorflow.js models to classify/infer detected hand gestures. The model inference can be plugged in to app workflows, which can enable easier user interactions and in turn make the app more accessible.

The primary goal of this project is to explore libraries, Tensorflow.js framework/models, to create the pipeline of accessing user webcam feed, detect and project user gestures on a web page. Additonal features will be explored to possibly perform transfer learning with new data, within the app and test new models, to turn the app into an accessibility tool.

## Libraries being used and explored

- React.js
- Tensorflow.js framework for Deep Learning
- Tensorflow.js pre-trained models

## Referenced resources

- [Real time hand pose estimation](https://www.youtube.com/watch?v=f7uBsb-0sGQ)
- [Real time gesture recognition](https://www.youtube.com/watch?v=9MTiQMxTXPE)
- [Mediapipe Hands](https://google.github.io/mediapipe/solutions/hands)
- [Fingerpose Documentation](https://openbase.com/js/fingerpose/documentation)
